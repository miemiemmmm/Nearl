{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141c9631",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5070dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.utils.data as Data\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dac302",
   "metadata": {},
   "source": [
    "# Movan Python P11, Regression 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d2a30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=1, out_features=30, bias=True)\n",
      "  (predict): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n",
      "0 th training  Loss of the data tensor(0.3190)\n",
      "100 th training  Loss of the data tensor(0.0121)\n",
      "200 th training  Loss of the data tensor(0.0111)\n"
     ]
    }
   ],
   "source": [
    "# 数据存在维度 中括号数量决定 而非真实数据量\n",
    "# pytorch 中只能处理二维数据， 所以用unsqueeze （现在似乎可以处理一维数据了）\n",
    "# Note: 现在已经弃用Variable\n",
    "x=torch.unsqueeze(torch.linspace(-1,1,1000), dim=1)  \n",
    "\n",
    "y=x.pow(2)+0.1*torch.normal(torch.zeros(*x.size()))\n",
    "\n",
    "LR=0.01\n",
    "BATCH_SIZE=32\n",
    "EPOCH=12\n",
    "\n",
    "# plt.scatter(x,y)\n",
    "# plt.show()\n",
    "\n",
    "plt.ion()  # 实时打印\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# torch_dataset=Data.TensorDataset(x,y)\n",
    "# print(torch_dataset)\n",
    "# loader=Data.DataLoader(torch_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 用Class定义Neural Network， 并且继承torch.nn.Module(官方用法)\n",
    "# Constructor 起始结构：\n",
    "# def __init__(): \n",
    "#     super(Net,self).__init__()\n",
    "# 两个function 最重要: __init__(), forward()\n",
    "class Net(torch.nn.Module):\n",
    "    # __init__(): 初始化神经网络，定义，类似构图过程\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        # 两个参数，多少个输入feature，多少个输出feature\n",
    "        # 隐藏层\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "        # 输出层\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)\n",
    "    \n",
    "    # forward() 才是正式搭建神经网络\n",
    "    def forward(self, x):\n",
    "        # 构建激励函数， 输入隐藏曾， 将区线弯曲\n",
    "        x=F.relu(self.hidden(x))   \n",
    "        \n",
    "        x=self.predict(x)          # input the output from first layer to the second layer. \n",
    "        return x\n",
    "# RMSprop, Momentum, Adam all better than SGD\n",
    "\n",
    "net = Net(1,30,1)\n",
    "print(net)\n",
    "# 许多默认参数，已经在Network定义时进行了初始化。 \n",
    "# Learning rate, 类似simulation 里的 timestep,\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5);   # 直接对net.parameters进行操作\n",
    "loss_func = torch.nn.MSELoss();\n",
    "for t in range(300):\n",
    "    prediction = net(x)\n",
    "    # 格式就是prediction在前，真实值在后\n",
    "    loss = loss_func(prediction, y)\n",
    "    # 每次梯度归零\n",
    "    # Gradient, 本质是导数， Loss function的微分\n",
    "    optimizer.zero_grad()\n",
    "    # 误差反向传递, 类似直接修改Net的loss 方便之后optimizer优化Net参数\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if t%5 == 0:\n",
    "        plt.cla()\n",
    "        plt.scatter(x,y)\n",
    "        plt.plot(x, prediction.data.numpy(), 'r-', lw=5)\n",
    "        plt.text(0.5, 0, 'loss=%.4f' % loss.data)\n",
    "        plt.pause(0.1)\n",
    "    if t%100 ==0:\n",
    "        print(t,\"th training \",\"Loss of the data\", loss.data)\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02);   # 直接对net.parameters进行操作\n",
    "loss_func = torch.nn.CrossEntropyLoss();  # 交叉熵， 计算softmax， 所有概率元素加起来等于1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacccec",
   "metadata": {},
   "source": [
    "# P12, Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9e77353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Net(\n",
      "  (hidden): Linear(in_features=2, out_features=20, bias=True)\n",
      "  (predict): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "n_data = torch.ones(100, 2)\n",
    "x0 = torch.normal(2*n_data, 1)\n",
    "y0 = torch.zeros(100)\n",
    "x1 = torch.normal(-2*n_data, 1)\n",
    "y1 = torch.ones(100)\n",
    "\n",
    "x = torch.cat((x0, x1) , 0).type(torch.FloatTensor)\n",
    "y = torch.cat((y0, y1), ).type(torch.LongTensor)\n",
    "\n",
    "# plt.scatter(x[:,0],x[:,1], c=y , s=100, lw=0, cmap = \"RdYlGn\")\n",
    "# plt.show()\n",
    "class Net(torch.nn.Module):\n",
    "    # __init__(): 初始化神经网络，定义，类似构图过程\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        # 两个参数，多少个输入feature，多少个输出feature\n",
    "        # 隐藏层\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "        # 输出层\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)\n",
    "    \n",
    "    # forward() 才是正式搭建神经网络\n",
    "    def forward(self, x):\n",
    "        # 构建激励函数， 输入隐藏曾， 将区线弯曲\n",
    "        x=F.relu(self.hidden(x))   \n",
    "        \n",
    "        x=self.predict(x)          # input the output from first layer to the second layer. \n",
    "        return x\n",
    "net=Net(2,20,2)\n",
    "print(net)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.05)\n",
    "loss_func=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(100):\n",
    "    # 输出一个列表，各项加和并不为1， 要通过softmax转化成概率\n",
    "    out = net(x)\n",
    "    loss = loss_func(out, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if t%2==0:\n",
    "        plt.cla()\n",
    "        prediction = torch.max(F.softmax(out, dim=1) ,1)[1]\n",
    "        pred_y = prediction.data.numpy().squeeze()\n",
    "        target_y = y.numpy(); \n",
    "        plt.scatter(x[:,0], x[:,1], c=prediction)\n",
    "        accuracy  = np.sum(pred_y == target_y) / len(target_y)\n",
    "#         print(accuracy)\n",
    "        plt.text(1.5, -4, \"Accuracy = %.2f\"%accuracy)\n",
    "        plt.pause(0.1)\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaba765",
   "metadata": {},
   "source": [
    "# P13, 快速搭建法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d744f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 类首字母用大写， function用小写\n",
    "# 自动对parameters进行优化\n",
    "\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10,2)\n",
    ")\n",
    "print(net2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296818b",
   "metadata": {},
   "source": [
    "# P14， 保存提取参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afbe22dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x=torch.unsqueeze(torch.linspace(-1,1,1000), dim=1)  \n",
    "\n",
    "y=x.pow(2)+0.1*torch.normal(torch.zeros(*x.size()))\n",
    "\n",
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1,10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10,1)\n",
    ")\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr = 0.5)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "for t in range(100):\n",
    "#     print(t)\n",
    "    prediction = net1(x); \n",
    "    loss = loss_func(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(net1)\n",
    "def save(Network):\n",
    "    # 保存整个Network\n",
    "    torch.save(Network, \"net.pkl\")\n",
    "    # 保存parameters\n",
    "    torch.save(Network.state_dict(), \"state.pkl\")\n",
    "\n",
    "def restore_net():\n",
    "    return torch.load(\"net.pkl\")\n",
    "\n",
    "def restore_params(Network):\n",
    "    Network.load_state_dict(torch.load(\"state.pkl\"))\n",
    "    print(Network)\n",
    "save(net1)\n",
    "\n",
    "net2 = \"\"\n",
    "net2 = restore_net()\n",
    "print(net2)\n",
    "restore_params(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57095eab",
   "metadata": {},
   "source": [
    "# P15 Mini Batch training: 批训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad880ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x7fddaf32a550>\n",
      "<enumerate object at 0x7fddb0a646e0>\n",
      "Epoch:  0 | Step:  0  | batch x:  [ 7.  5. 10.  8.  2.]  | batch y: [4. 6. 1. 3. 9.]\n",
      "Epoch:  0 | Step:  1  | batch x:  [3. 9. 4. 6. 1.]  | batch y: [ 8.  2.  7.  5. 10.]\n",
      "Epoch:  1 | Step:  0  | batch x:  [6. 5. 3. 1. 4.]  | batch y: [ 5.  6.  8. 10.  7.]\n",
      "Epoch:  1 | Step:  1  | batch x:  [ 9.  8.  2. 10.  7.]  | batch y: [2. 3. 9. 1. 4.]\n",
      "Epoch:  2 | Step:  0  | batch x:  [10.  1.  6.  2.  5.]  | batch y: [ 1. 10.  5.  9.  6.]\n",
      "Epoch:  2 | Step:  1  | batch x:  [9. 7. 4. 8. 3.]  | batch y: [2. 4. 7. 3. 8.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "\n",
    "# 如果非batch size的整数倍，最后一个size包含其他未训练的数据\n",
    "# 如果batch size大于dataset,则只训练一次\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "x=torch.linspace(1,10,10)\n",
    "y=torch.linspace(10,1,10)\n",
    "# print(x, y)\n",
    "\n",
    "# 定义数据库，将所有data放进数据库\n",
    "dataset=Data.TensorDataset(x, y)\n",
    "\n",
    "loader = Data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(dataset)\n",
    "print(enumerate(loader))\n",
    "\n",
    "# epoch 总共将数据循环的次数\n",
    "for epoch in range(3):\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        print(\"Epoch: \", epoch, \"| Step: \", step, \" | batch x: \", batch_x.numpy(), \" | batch y:\",batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52129d4c",
   "metadata": {},
   "source": [
    "# P17， Optimizer, 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74da85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypter-parameters, 用大写\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 12\n",
    "\n",
    "x=torch.unsqueeze(torch.linspace(-1,1,1000), dim=1)  \n",
    "\n",
    "y=x.pow(2)+0.1*torch.normal(torch.zeros(*x.size()))\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "loader = Data.DataLoader(\n",
    "    dataset = torch_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    # __init__(): 初始化神经网络，定义，类似构图过程\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        # 两个参数，多少个输入feature，多少个输出feature\n",
    "        # 一个隐藏层，有20个神经元\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "        # 输出层\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)\n",
    "    \n",
    "    # forward() 才是正式搭建神经网络\n",
    "    def forward(self, x):\n",
    "        # 构建激励函数， 输入隐藏曾， 将区线弯曲\n",
    "        x=F.relu(self.hidden(x))\n",
    "        x=self.predict(x)          # input the output from first layer to the second layer. \n",
    "        return x\n",
    "\n",
    "net_SGD = Net(1,20,1)\n",
    "net_Momentum = Net(1,20,1)\n",
    "net_RMSprop = Net(1,20,1)\n",
    "net_Adam = Net(1,20,1)\n",
    "nets=[net_SGD ,net_Momentum , net_RMSprop, net_Adam]\n",
    "\n",
    "opt_SGD = torch.optim.SGD(net_SGD.parameters(), lr=LR)\n",
    "opt_Momentum = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.8)\n",
    "opt_RMSprop = torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=0.9)\n",
    "opt_Adam = torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(0.9, 0.99))\n",
    "optimizers=[opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam]\n",
    "\n",
    "# RMSprop, Adam 整体来说比较优秀\n",
    "\n",
    "loss_func=torch.nn.MSELoss()\n",
    "Losses=[[],[],[],[]]\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "#     print(epoch)\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        for net, opt, l_his in zip(nets, optimizers, Losses):\n",
    "            output = net(batch_x)\n",
    "            loss = loss_func(output, batch_y)\n",
    "            opt.zero_grad(); \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            l_his.append(loss.item())\n",
    "labels = [\"SGD\",\"Momentum\", \"RMSprop\",\"Adam\"]\n",
    "plt.clf()\n",
    "for i, l_his in enumerate(Losses):\n",
    "    plt.plot(l_his, label=labels[i])\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9d99d",
   "metadata": {},
   "source": [
    "# P19. Convolutional neural network (CNN)\n",
    "1. 先对图片小部分进行处理 （收集一小块像素区域， 整理信息，呈现一些特征）。加强数据的连续性和图片的理解\n",
    "2. 用前边提取到的边缘信息，进行重复特征提取，总结出更高级的数据结构\n",
    "3. 然后放入全连接神经网络，进行结果分类\n",
    "\n",
    "<span>256\\*256\\*RGB -> 128\\*128\\*16 -> 64\\*64\\*64 -> 32\\*32\\*256 <br></span>\n",
    "<span>将信息压缩，增高 <br></span>\n",
    "<span> 比较常用的CNN结构</span>\n",
    "- Classifier\n",
    "- Fully Connect \n",
    "- Fully Connect\n",
    "- Max Pooling\n",
    "- Convolution\n",
    "- Max Pooling\n",
    "- Convulution\n",
    "- Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "850a6682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144\n",
      "262144\n",
      "262144\n",
      "262144\n"
     ]
    }
   ],
   "source": [
    "print(256*256*4)\n",
    "print(128*128*16)\n",
    "print(64*64*64)\n",
    "print(32*32*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c0d5dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n",
      "Epoch:  0 | train loss 2.3003 | test accuracy: 0.21\n",
      "Epoch:  0 | train loss 0.3709 | test accuracy: 0.81\n",
      "Epoch:  0 | train loss 0.3640 | test accuracy: 0.90\n",
      "Epoch:  0 | train loss 0.1904 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss 0.1920 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss 0.1159 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss 0.1484 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss 0.3370 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss 0.3040 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss 0.1221 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss 0.0861 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.0526 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.0919 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.0758 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.1782 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.0575 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.0831 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.0543 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.0780 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss 0.0325 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss 0.0730 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.1089 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss 0.2639 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss 0.1561 | test accuracy: 0.98\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] read number\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001\n",
    "DOWNLOAD_MNIST=False\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=True,\n",
    "    transform = torchvision.transforms.ToTensor(), # (0,1) numpy array # RGB 值从 0-255压缩至(0-1）\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "print(train_data.train_data.size())\n",
    "print(train_data.train_labels.size())\n",
    "# plt.clf()\n",
    "# plt.imshow(train_data.train_data[6000].numpy(), cmap=\"gray\")\n",
    "# plt.show()\n",
    "\n",
    "train_loader = Data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=False\n",
    ")\n",
    "# 将 0-255 归一化\n",
    "test_x = torch.unsqueeze(test_data.data, dim=1).type(torch.FloatTensor)[:2000]/255 \n",
    "test_y = test_data.targets[:2000]\n",
    "\n",
    "# print(y[0])\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels  = 1,\n",
    "                out_channels = 16,   # 卷积核的 深度\n",
    "                kernel_size = 5,     # 卷积核的 长 和 宽\n",
    "                stride = 1 ,         # 1 个像素跳跃\n",
    "                padding = 2 ,       # 边缘补充0， 防止卷积核对图片进行裁切\n",
    "            ),   # 卷积核 --> (16,28,28)\n",
    "            nn.ReLU(),   # --> (16,28,28)\n",
    "            nn.MaxPool2d(kernel_size=2),  # --> (16,14,14) stride 默认等于kernel_size, 所以除以2\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),   # --> (32,14,14) \n",
    "            nn.ReLU(),                    # --> (32,14,14) \n",
    "            nn.MaxPool2d(kernel_size=2)   # --> (32,7,7)  三维的数据\n",
    "        )\n",
    "        \n",
    "        # 进入Linear层之前要把Convolution层的数据展开成一维\n",
    "        self.out = nn.Linear(32*7*7, 10)\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=x.view(x.size(0), -1)\n",
    "        output=self.out(x)\n",
    "        return output, x\n",
    "\n",
    "    \n",
    "    \n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "# for (b_x, b_y) in train_loader:\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x,y) in enumerate(train_loader):\n",
    "        output = cnn(x)[0]\n",
    "#         print(output)\n",
    "        loss = loss_func(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step%50 ==0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output[0],1)[1].data.squeeze()\n",
    "            accuracy = sum(pred_y == test_y) /test_y.size(0)\n",
    "            print(\"Epoch: \", epoch, \"| train loss {:.4f}\".format(loss.item()), \"| test accuracy: {:.2f}\".format(accuracy))\n",
    "            \n",
    "            \n",
    "\n",
    "test_output = cnn(test_x[:10])    \n",
    "pred_y = torch.max(test_output[0], 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, \"prediction number\")\n",
    "print(test_y[:10].numpy(), \"read number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069f292",
   "metadata": {},
   "source": [
    "# P21. Recurrent Neural Network, (RNN) 循环神经网络\n",
    "普通神经网络因为参数多次反向传递，可能会有梯度爆炸(gradient explosion)和梯度消失(梯度弥散， gradient vanishing)\n",
    "<span>LSTM 用于解决上述问题，比普通RNN多了输入控制器，输出控制器，和记忆控制器<br></span>\n",
    "<span>存在全局主线剧情:\n",
    "- 如果支线剧情对于主线影响巨大，输入控制器会将其重要程度写入剧情\n",
    "- 如果支线剧情对于主线影响巨大，记忆控制器会将之前部分主线遗忘，并替换新剧情\n",
    "- 依据主线和支线进行预测\n",
    "</span>\n",
    "\n",
    "<span>用 RNN 观看 MNIST 的数字, RNN 输入为一串序列，所以每一行的像素进行一个序列的输入 </span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8893dd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff8856b5d50>\n",
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([64, 28, 28])\n",
      "Epoch:  0 | train loss 2.3090 | test accuracy: 0.09\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "Epoch:  0 | train loss 0.9369 | test accuracy: 0.64\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "Epoch:  0 | train loss 0.5575 | test accuracy: 0.79\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "Epoch:  0 | train loss 0.5577 | test accuracy: 0.82\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([16, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# MNIST 分类问题\n",
    "# TODO: format of the input data. \n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28\n",
    "INPUT_SIZE = 28\n",
    "LR = 0.01\n",
    "DOWNLOAD_MNIST = False\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor()    \n",
    ")\n",
    "# 将 0-255 归一化\n",
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255 \n",
    "test_y = test_data.test_labels.numpy()[:2000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = INPUT_SIZE,   # 每个时间点输入28个像素点\n",
    "            hidden_size = 64,          # 隐藏层节点个数\n",
    "            num_layers = 1,            # 隐藏层的层数\n",
    "            batch_first = True,        # 输入数据中，（batch， time_step, input）batch 在第几个维度. 通常将其放在第一个维度\n",
    "        )\n",
    "        # input 为一行28个像素， time step 代表 28 个时间序列， batch带表一个batch\n",
    "        self.out = nn.Linear(64,10)\n",
    "    def forward(self, x):\n",
    "        # h_n 和 h_c 共同代表 hidden state，h_n 代表主线，h_c 代表支线\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None) \n",
    "        out = self.out(r_out[:, -1, :])    # 数据结构为(batch， time step， input)\n",
    "        return out\n",
    "    \n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        b_x = b_x.view(-1, TIME_STEP, INPUT_SIZE)\n",
    "        print(b_x.size())\n",
    "        output = rnn(b_x)\n",
    "        \n",
    "        loss = loss_func(output , b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step%50 == 0:\n",
    "            test_output = rnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = (pred_y == test_y).astype(int).sum() / test_y.size\n",
    "            print(\"Epoch: \", epoch, \"| train loss {:.4f}\".format(loss.item()), \"| test accuracy: {:.2f}\".format(accuracy))\n",
    "            \n",
    "#         print(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1cd1247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_iterator', 'batch_sampler', 'batch_size', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']\n"
     ]
    }
   ],
   "source": [
    "print(dir(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43c1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e9963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8da25012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Epoch:  0 | train loss: 2.3047 | test accuracy: 0.19\n",
      "Epoch:  0 | train loss: 0.8026 | test accuracy: 0.59\n",
      "Epoch:  0 | train loss: 0.6238 | test accuracy: 0.75\n",
      "Epoch:  0 | train loss: 0.6579 | test accuracy: 0.83\n",
      "Epoch:  0 | train loss: 0.5053 | test accuracy: 0.85\n",
      "Epoch:  0 | train loss: 0.4139 | test accuracy: 0.87\n",
      "Epoch:  0 | train loss: 0.3088 | test accuracy: 0.90\n",
      "Epoch:  0 | train loss: 0.2748 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.1646 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.1640 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.1498 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.1521 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1171 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0985 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.3427 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0276 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.1273 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.1653 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1945 | test accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = True   # set to True if haven't download the data\n",
    "\n",
    "\n",
    "# Mnist digital dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")\n",
    "\n",
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()\n",
    "\n",
    "# Data Loader for easy mini-batch return in training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor())\n",
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)\n",
    "test_y = test_data.test_labels.numpy()[:2000]    # covert to numpy array\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):        # gives batch data\n",
    "        \n",
    "        b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)\n",
    "#         print(b_x.size())\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc8fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9838cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "a = np.ones((1, 4))\n",
    "b = np.ones(\n",
    "    16,\n",
    ")\n",
    "print(a)\n",
    "print(b)\n",
    "print(a + b[:,np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48ef76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
